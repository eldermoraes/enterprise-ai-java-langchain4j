# Configura a URL base do servidor Ollama.
quarkus.langchain4j.ollama.base-url=http://localhost:11434/

# Define o ID do modelo que o Langchain4j irá invocar no Ollama.
quarkus.langchain4j.ollama.chat-model.model-id=gpt-oss:20b

# Define um timeout para a chamada.
# Se o modelo demorar mais de 60s para responder, a chamada falhará.
quarkus.langchain4j.ollama.timeout=60s

# Aponta para o diretório que contém nossos documentos.
# O Easy RAG irá ler todos os arquivos neste local na inicialização.
quarkus.langchain4j.easy-rag.path=src/main/resources/rag

# --- Configurações do EasyRAG (desativadas) ---
# quarkus.langchain4j.easy-rag.path=src/main/resources/rag
# quarkus.langchain4j.easy-rag.max-segment-size=100
# quarkus.langchain4j.easy-rag.max-overlap-size=20

# --- Configuração do Embedding Model ---
quarkus.langchain4j.ollama.embedding-model.model-id=nomic-embed-text

# --- Configuração do PgVector ---
# A dimensão do vetor DEVE corresponder à do seu EmbeddingModel. O modelo 'nomic-embed-text' usa vetores de 768 dimensões.
quarkus.langchain4j.pgvector.register-vector-pg-extension=true
quarkus.langchain4j.pgvector.dimension=768
quarkus.langchain4j.pgvector.table=travel_embeddings
quarkus.langchain4j.pgvector.drop-table-first=true